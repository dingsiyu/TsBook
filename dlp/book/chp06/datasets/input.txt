我试验用生成对抗网络来生成猫脸的各种图片。针对不同的分辨率，我采用了几种不同的方法，包括DCGAN、WGAN与WGAN-GP，训练样本源自一个有着上万张猫图的图片库。我找的是那些猫脸处在正中的图片（用人眼生看，花了我好几个小时……说起来都是泪），共有9304张分辨率大于64x64的图片，以及6445张分辨率大于128x128的图片。DCGAN可以很好的收敛，只用了209次迭代，大概两三个小时，就产生了非常有真实感的图片。但是需要进行一些调整才能达到这个效果。众所周知，GAN的生成器和判别器必须势均力敌，才能产生良好的效果。我的DCGAN对生成器和判别器分别设定了不同的学习速率，这样才使得二者势均力敌，从而能得出很好的效果。当处理64x64的图片的时候，最好的判别器的学习速率是0.00005，生成器的速率是0.0002。如下图所示，没有产生模式坍塌(mode collapse)。图片漂亮吧！但上述办法用来处理128x128的图片，就会失效。但是，我用SeLUs替换了batch归一化和ReLus，在学习速率保持不变的情况下，也取得了一定的效果。只不过过程非常慢，大概要用6个多小时。SeLUs是自归一的，因此就不需要用batch归一化了。SeLU才刚诞生不久，所以基本上在GAN上没有什么深入的研究。不过据我观察，SeLU极大的提高了GAN的稳定性。这次生成的猫不像上次的那么漂亮，并且有很多黑猫长的差不多，明显地产生了“多样性缺失”现象。这也很好解释，因为这次是在6445个大于128x128的图片上训练，而上次是在9304个图片上训练，训练数据少了不少。不过，这次有些猫也相当好看，清晰度比原来的高，所以我仍然觉得这次也是成功的。WGAN收敛的很慢，大概用了四五个小时，600多次迭代。并且只在64个隐层神经元成功了。128个神经元的时候失败了。对DCGAN，虽然要调整学习速率，但是一旦调整了，你马上能看到效果。对WGAN，很难马上看到效果，只有让网络多跑几个迭代，才能看到效果。
观察图片的话，有非常明显的模式坍塌(mode collapse)。还有很多猫有异盲证，一些猫一只眼睁着，一个眼闭着；还有一些猫鼻子畸形。总体上看，WGAN的效果不如DCGAN。但是也许是因为我用的神经网络的结构太简单，所以不好在二者之间做明确的判断，哪个更好。还有，WGAN似乎陷入了局部最优。到目前为止，WGAN还是令我有点失望。
WGAN-GP是WGAN的改进版本，也许能够解决上面的问题。2017年的Gulrajani等人发表的论文中，提到他们能训练101层的神经网络。所以也许我的用5层128个神经元的方法生成猫的方法有问题。亚当优化器(Adam optimizer)也能降低种类坍塌和局部最优的风险。
WGAN-GP的生成器收敛的非常慢，大概在六个小时以上。但是它的好处是不需要调整任何超参。比如，可以任意调整学习速率，调大或者调小，都不会造成任何问题。这一点上，WGAN-GP用起来很舒心，不像其他算法调整超参那么辛苦。
而且该方法生成的猫的种类和样式非常多，没有明显的模式坍塌(mode collapse)。这是对WGAN的的一个主要的改进。另一方面，图片有点模糊不清，好像是低分辨率的图片又被放大了一倍。我也不确定具体的原因，可能是Wasserstein距离的导致的。我觉得可以使用不同的学习速率和网络结构优化结果。这需要做更进一步的研究，但我确信这里有很大的提高空间。
LSGAN和前面几个方法不同。LSGAN用最小二乘法来最小化判别器的输出和真实结果差值。该方法的推荐设置为：在判别器端，用1表示真实图像，0表示假的图像；在生成器端，用1表示假的图像。2017年Hejlm等人在论文中又提出了新的建议：在判别器端，1表示真实图像，0表示假的图像；但是在生成器端，用0.5表示假的图像。
我现在还没有时间全面研究这个方法。但是看起来，这个方法非常稳定，并且生成的图片中的猫也很漂亮。虽然该方法通常挺稳定的，但是有一次，出现了梯度爆炸，最后生成的结果嘛也不是。下图展示了第31和32次迭代的结果：
所以该方法也不是百分百的稳定，不稳定的时候结果还非常糟糕。对Adam优化器选择一个较好的超参可以有效阻止该问题的发生。该方法的优点是不用像DCGAN那样调整学习速率，并且不发生问题的时候(发生问题的概率还是很低的)，结果还是很不错的，猫的图片也很漂亮。
我们提出了一种基于LSTM的神经网络模型，和把每个输入文本都独立编码为一个语义向量的模型不同的是，该模型同时读取前提和假设两个描述的文本序列并判断假设是否成立。我们在模型中加入了Attention机制来找出假设和前提文本中词/短语之间的对齐关系。……加入Attention机制能够使模型在实验结果上有2.6个点的提升，这是目前数据集上取得的最好结果…
可以说，这几年在机器学习领域最亮最火最耀眼的新思想就是生成对抗网络了。这一思想不光催生了很多篇理论论文，也带来了层出不穷的实际应用。Yann LeCun 本人也曾毫不吝啬地称赞过：这是这几年最棒的想法！
大家都知道，LeCun 是无监督学习的头号号召者。生成对抗网络这种靠数据和模型自己的内部对抗来实现无监督学习的模型正好给人工智能的自我学习能力带来了一线曙光！
大神 Ian Goodfellow（这姓本身就很学术）是神经网络奠基人 Yoshua Bengio 的学生（跟相声一样，学术界也讲究个师承和门派。收不收学费就因人而异了。学校的发票应该还是有的）。继承了 Bengio 的步伐，Ian 在 2014 年的一篇 GAN 论文也是震惊世界，被认为是带领人类走向机器学习下一个纪元的开创性方法。Ian 在谷歌带完这一波节奏之后，便加入了「硅谷钢铁侠」Elon Musk 的 OpenAI。
OpenAI 这家酷炫的研究所是非营利的，主要目标就是做深度的人工智能研究来为人类造福，或防止人工智能失控而灭绝人类。当然，这只是个口号，本质上其实就是有钱人撒钱养一帮学界大神来提升自己在圈内的逼格。当然，他们也不计利润和 IP 地开源了大量代码和框架，这也是造福工业界和学术界的好事。GAN 作为 OpenAI 的首个高逼格成果，也在这两年得到了长足的优化和拓展。
密度（概率）估计：就是说在不了解事件概率分布的情况下，先假设随机分布，然后通过数据观测来确定真正的概率密度是怎样的。
这里就是我们的生成模型了。如图所示，它把噪声数据 z（也就是我们说的假数据）通过生成模型 G，伪装成了真实数据 x。（当然，因为 GAN 依旧是一个神经网络，你的生成模型需要是可微的（differentiable））
训练的过程也非常直观，你可以选择任何类 SGD 的方法（因为 A 和 B 两个竞争者都是可微的网络）。并且你要同时训练两组数据：一组真实的训练数据和一组由骗子 A 生成的数据。当然，你也可以一组训练每跑一次时，另一组则跑 K 次，这样可以防止其中一个跟不上节奏。
同样，既然要用类 SGD 优化，我们就需要一个目标函数（objective function）来判断和监视学习的成果。在这里，J(D) 代表判别网络（也就是警察 B）的目标函数——一个交叉熵（cross entropy）函数。其中左边部分表示 D 判断出 x 是真 x 的情况，右边部分则表示 D 判别出的由生成网络 G（也就是骗子）把噪音数据 z 给伪造出来的情况。
这样，同理，J(G) 就是代表生成网络的目标函数，它的目的是跟 D 反着干，所以前面加了个负号（类似于一个 Jensen-Shannon（JS）距离的表达式）。
这其实就是我们熟悉的最小最大博弈（minimax game）：两个人的零和博弈，一个想最大，另一个想最小。那么，我们要找的均衡点（也就是纳什均衡）就是 J(D) 的鞍点（saddle point）。
如图所示，我们手上有真实数据（黑色点，data）和模型生成的伪数据（绿色线，model distribution，是由我们的 z 映射过去的）（画成波峰的形式是因为它们都代表着各自的分布，其中纵轴是分布，横轴是我们的 x）。而我们要学习的 D 就是那条蓝色的点线，这条线的目的是把融在一起的 data 和 model 分布给区分开。写成公式就是 data 和 model 分布相加做分母，分子则是真实的 data 分布。
我们最终要达到的效果是：D 无限接近于常数 1/2。换句话说就是要 Pmodel 和 Pdata 无限相似。这个时候，我们的 D 分布再也没法分辨出真伪数据的区别了。这时候，我们就可以说我们训练出了一个炉火纯青的造假者（生成模型）。